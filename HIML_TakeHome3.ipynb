{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIML TakeHome3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from os import getcwd\n",
    "from os.path import join \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0  8192\n",
       "1     5\n",
       "2   850\n",
       "3   850"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = join(getcwd(),'data','data3SS2009.mat')\n",
    "\n",
    "mat_contents = sio.loadmat(fname)\n",
    "\n",
    "dataset = mat_contents['dataset']\n",
    "\n",
    "N, Chno, Nc = dataset.shape\n",
    "# N: number of samples\n",
    "# Chno: number of channels\n",
    "# Nc: number of cases\n",
    "\n",
    "Y = mat_contents['labels'].reshape(Nc)\n",
    "\n",
    "# print sizes \n",
    "pd.DataFrame(np.array([N, Chno, Nc,len(Y)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoRegression + PCA + scaling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoRegression\n",
    "X_ = np.empty((0, 850), float)\n",
    "for i in range(4):\n",
    "    chdata = dataset[:,i+1,:]\n",
    "    ch_corr = []\n",
    "    for j in range(np.shape(chdata)[1]):\n",
    "        res = AutoReg(chdata[:,j],lags=29,old_names=False).fit()\n",
    "        ch_corr.append(res.params)\n",
    "    \n",
    "    X_ = np.append(X_, np.array(ch_corr).transpose() , axis=0)\n",
    "X = np.transpose(X_)\n",
    "\n",
    "# np.shape(X)\n",
    "\n",
    "# pca\n",
    "pca = PCA(random_state=0, whiten=True, n_components=.95)\n",
    "X_pca = pca.fit_transform(X)\n",
    "Xpca_scaled = MinMaxScaler(feature_range=(-1,1)).fit_transform(X_pca)\n",
    "\n",
    "# nPC = np.shape(Xpca_scaled)[1]\n",
    "# nPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Xpca_scaled,Y,test_size=0.25,random_state=42)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9107981220657277"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\",max_iter=200)\n",
    "softmax_reg.fit(X_train,Y_train)\n",
    "softmax_reg.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelo classificador linear, a acurácia em relação ao test-set foi de aprox. 91%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classification\n",
    "\n",
    "Varia-se o tipo de kernel para entre rbf (Radial Basis Function), sigmoid e polinomial. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9248826291079812, 0.784037558685446, 0.9107981220657277]\n"
     ]
    }
   ],
   "source": [
    "# variando o tipo de kernel\n",
    "kernels = ['rbf','sigmoid','poly']\n",
    "scores_SVM = []\n",
    "for i in range(len(kernels)):\n",
    "    clf = svm.SVC(kernel=kernels[i],random_state=0)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    scores_SVM.append(clf.score(X_test,Y_test))\n",
    "print(scores_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que com o rbf, a acurácia do classificador em relaçao ao test-set foi de 92.5%. \n",
    "\n",
    "Para o caso polinomial, varia-se o grau da funçao de 2 a 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9154929577464789, 0.9107981220657277, 0.9154929577464789, 0.9014084507042254]\n"
     ]
    }
   ],
   "source": [
    "# com o kernel = poly, varia o grau da função polinomial\n",
    "degs = [2,3,4,5]\n",
    "scores_SVM_poly = []\n",
    "for i in range(len(degs)):\n",
    "    clf = svm.SVC(kernel='poly',degree=degs[i],random_state=0)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    scores_SVM_poly.append(clf.score(X_test,Y_test))\n",
    "print(scores_SVM_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com grau 2 e 4, obtemos os melhores resultados, ~91.5%\n",
    "\n",
    "Para o caso do rbf, varia-se o gamma, que determina a influência de um exemplo de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8403755868544601, 0.92018779342723, 0.9295774647887324]\n"
     ]
    }
   ],
   "source": [
    "# com o kernel = rbf, varia o gamma\n",
    "gammas = [0.1,1,10]\n",
    "scores_SVM_gam = []\n",
    "for i in range(len(gammas)):\n",
    "    clf = svm.SVC(kernel='rbf',gamma=gammas[i],random_state=0)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    scores_SVM_gam.append(clf.score(X_test,Y_test))\n",
    "print(scores_SVM_gam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com gamma = 10, obtemos uma acurácia de ~93%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN classification\n",
    "\n",
    "Explora-se o número de vizinhos do classificador kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9295774647887324, 0.9389671361502347, 0.9342723004694836, 0.92018779342723, 0.92018779342723, 0.9248826291079812, 0.9248826291079812, 0.9154929577464789, 0.9154929577464789, 0.9154929577464789, 0.9154929577464789]\n"
     ]
    }
   ],
   "source": [
    "# variando o número de vizinhos\n",
    "Nneig = [i for i in range(5,16)]\n",
    "scores_kNN = []\n",
    "for i in range(len(Nneig)):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=int(Nneig[i]))\n",
    "    clf.fit(X_train,Y_train)\n",
    "    scores_kNN.append(clf.score(X_test,Y_test))\n",
    "print(scores_kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com 6 vizinhos, obtém-se uma acurácia de 93.4%.\n",
    "\n",
    "A seguir, varia-se o parâmetro da métrica Minkowski. Quando p =1, usa-se a manhattan_distance, p = 2, euclidean_distance , e p qualquer, minkowski_distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9248826291079812, 0.9389671361502347, 0.92018779342723, 0.9154929577464789]\n"
     ]
    }
   ],
   "source": [
    "# variando o power parameter for the Minkowski metric\n",
    "ps = [1,2,3,4]\n",
    "scores_kNN_ps = []\n",
    "for i in range(len(ps)):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=6,p=ps[i])\n",
    "    clf.fit(X_train,Y_train)\n",
    "    scores_kNN_ps.append(clf.score(X_test,Y_test))\n",
    "print(scores_kNN_ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para p = 2, obtém-se umma acurácia de 93.9% (a melhor entre todos os testes realizados)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1cbc199116ca0050f15b4a096ee5586221393ef42f89efdf0ba89fccf25361f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
